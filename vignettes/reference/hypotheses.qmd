# hypotheses {.unnumbered}

(Non-)Linear Tests for Null Hypotheses, Joint Hypotheses, Equivalence, Non Superiority, and Non Inferiority

## Description

<p>Uncertainty estimates are calculated as first-order approximate standard errors for linear or non-linear functions of a vector of random variables with known or estimated covariance matrix. In that sense, <code>hypotheses</code> emulates the behavior of the excellent and well-established car::deltaMethod and car::linearHypothesis functions, but it supports more models; requires fewer dependencies; expands the range of tests to equivalence and superiority/inferiority; and offers convenience features like robust standard errors.
</p>
<p>To learn more, read the hypothesis tests vignette, visit the
package website, or scroll down this page for a full list of vignettes:
</p>

<ul>
<li> <p><a href="https://marginaleffects.com/vignettes/hypothesis.html">https://marginaleffects.com/vignettes/hypothesis.html</a>
</p>
</li>
<li> <p><a href="https://marginaleffects.com/">https://marginaleffects.com/</a>
</p>
</li></ul>

<p>Warning #1: Tests are conducted directly on the scale defined by the <code>type</code> argument. For some models, it can make sense to conduct hypothesis or equivalence tests on the <code>"link"</code> scale instead of the <code>"response"</code> scale which is often the default.
</p>
<p>Warning #2: For hypothesis tests on objects produced by the <code>marginaleffects</code> package, it is safer to use the <code>hypothesis</code> argument of the original function.  Using <code>hypotheses()</code> may not work in certain environments, in lists, or when working programmatically with *apply style functions.
</p>
<p>Warning #3: The tests assume that the <code>hypothesis</code> expression is (approximately) normally distributed, which for non-linear functions of the parameters may not be realistic. More reliable confidence intervals can be obtained using the <code>inferences()</code> function with <code>method = "boot"</code>.
</p>


## Usage

<pre><code class='language-R'>hypotheses(
  model,
  hypothesis = NULL,
  vcov = NULL,
  conf_level = 0.95,
  df = Inf,
  equivalence = NULL,
  joint = FALSE,
  joint_test = "f",
  FUN = NULL,
  numderiv = "fdforward",
  ...
)
</code></pre>


## Arguments

<table>
<tr style="vertical-align: top;"><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code>model</code></td>
<td>
<p>Model object or object generated by the <code>comparisons()</code>, <code>slopes()</code>, <code>predictions()</code>, or <code>marginal_means()</code> functions.</p>
</td></tr>
<tr style="vertical-align: top;"><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code>hypothesis</code></td>
<td>
<p>specify a hypothesis test or custom contrast using a numeric value, vector, or matrix, a string, or a string formula.
</p>

<ul>
<li><p> Numeric:
</p>

<ul>
<li><p> Single value: the null hypothesis used in the computation of Z and p (before applying <code>transform</code>).
</p>
</li>
<li><p> Vector: Weights to compute a linear combination of (custom contrast between) estimates. Length equal to the number of rows generated by the same function call, but without the <code>hypothesis</code> argument.
</p>
</li>
<li><p> Matrix: Each column is a vector of weights, as describe above, used to compute a distinct linear combination of (contrast between) estimates. The column names of the matrix are used as labels in the output.
</p>
</li></ul>

</li>
<li><p> String formula to specify linear or non-linear hypothesis tests. If the <code>term</code> column uniquely identifies rows, terms can be used in the formula. Otherwise, use <code>b1</code>, <code>b2</code>, etc. to identify the position of each parameter. The <code style="white-space: pre;">&#8288;b*&#8288;</code> wildcard can be used to test hypotheses on all estimates. Examples:
</p>

<ul>
<li> <p><code>hp = drat</code>
</p>
</li>
<li> <p><code>hp + drat = 12</code>
</p>
</li>
<li> <p><code>b1 + b2 + b3 = 0</code>
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;b* / b1 = 1&#8288;</code>
</p>
</li></ul>

</li>
<li><p> String:
</p>

<ul>
<li><p> &quot;pairwise&quot;: pairwise differences between estimates in each row.
</p>
</li>
<li><p> &quot;reference&quot;: differences between the estimates in each row and the estimate in the first row.
</p>
</li>
<li><p> &quot;sequential&quot;: difference between an estimate and the estimate in the next row.
</p>
</li>
<li><p> &quot;revpairwise&quot;, &quot;revreference&quot;, &quot;revsequential&quot;: inverse of the corresponding hypotheses, as described above.
</p>
</li></ul>

</li>
<li><p> See the Examples section below and the vignette: https://marginaleffects.com/vignettes/hypothesis.html
</p>
</li></ul>
</td></tr>
<tr style="vertical-align: top;"><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code>vcov</code></td>
<td>
<p>Type of uncertainty estimates to report (e.g., for robust standard errors). Acceptable values:
</p>

<ul>
<li><p> FALSE: Do not compute standard errors. This can speed up computation considerably.
</p>
</li>
<li><p> TRUE: Unit-level standard errors using the default <code>vcov(model)</code> variance-covariance matrix.
</p>
</li>
<li><p> String which indicates the kind of uncertainty estimates to return.
</p>

<ul>
<li><p> Heteroskedasticity-consistent: <code>"HC"</code>, <code>"HC0"</code>, <code>"HC1"</code>, <code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, <code>"HC4m"</code>, <code>"HC5"</code>. See <code>?sandwich::vcovHC</code>
</p>
</li>
<li><p> Heteroskedasticity and autocorrelation consistent: <code>"HAC"</code>
</p>
</li>
<li><p> Mixed-Models degrees of freedom: &quot;satterthwaite&quot;, &quot;kenward-roger&quot;
</p>
</li>
<li><p> Other: <code>"NeweyWest"</code>, <code>"KernHAC"</code>, <code>"OPG"</code>. See the <code>sandwich</code> package documentation.
</p>
</li></ul>

</li>
<li><p> One-sided formula which indicates the name of cluster variables (e.g., <code>~unit_id</code>). This formula is passed to the <code>cluster</code> argument of the <code>sandwich::vcovCL</code> function.
</p>
</li>
<li><p> Square covariance matrix
</p>
</li>
<li><p> Function which returns a covariance matrix (e.g., <code>stats::vcov(model)</code>)
</p>
</li></ul>
</td></tr>
<tr style="vertical-align: top;"><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code>conf_level</code></td>
<td>
<p>numeric value between 0 and 1. Confidence level to use to build a confidence interval.</p>
</td></tr>
<tr style="vertical-align: top;"><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code>df</code></td>
<td>
<p>Degrees of freedom used to compute p values and confidence intervals. A single numeric value between 1 and <code>Inf</code>. When <code>df</code> is <code>Inf</code>, the normal distribution is used. When <code>df</code> is finite, the <code>t</code> distribution is used. See insight::get_df for a convenient function to extract degrees of freedom. Ex: <code>slopes(model, df = insight::get_df(model))</code></p>
</td></tr>
<tr style="vertical-align: top;"><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code>equivalence</code></td>
<td>
<p>Numeric vector of length 2: bounds used for the two-one-sided test (TOST) of equivalence, and for the non-inferiority and non-superiority tests. See Details section below.</p>
</td></tr>
<tr style="vertical-align: top;"><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code>joint</code></td>
<td>
<p>Joint test of statistical significance. The null hypothesis value can be set using the <code>hypothesis</code> argument.
</p>

<ul>
<li><p> FALSE: Hypotheses are not tested jointly.
</p>
</li>
<li><p> TRUE: All parameters are tested jointly.
</p>
</li>
<li><p> String: A regular expression to match parameters to be tested jointly. <code>grep(joint, perl = TRUE)</code>
</p>
</li>
<li><p> Character vector of parameter names to be tested. Characters refer to the names of the vector returned by <code>coef(object)</code>.
</p>
</li>
<li><p> Integer vector of indices. Which parameters positions to test jointly.
</p>
</li></ul>
</td></tr>
<tr style="vertical-align: top;"><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code>joint_test</code></td>
<td>
<p>A character string specifying the type of test, either &quot;f&quot; or &quot;chisq&quot;. The null hypothesis is set by the <code>hypothesis</code> argument, with default null equal to 0 for all parameters.</p>
</td></tr>
<tr style="vertical-align: top;"><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code>FUN</code></td>
<td>
<p><code>NULL</code> or function.
</p>

<ul>
<li> <p><code>NULL</code> (default): hypothesis test on a model's coefficients, or on the quantities estimated by one of the <code>marginaleffects</code> package functions.
</p>
</li>
<li><p> Function which accepts a model object and returns a numeric vector or a data.frame with two columns called <code>term</code> and <code>estimate</code>. This argument can be useful when users want to conduct a hypothesis test on an arbitrary function of quantities held in a model object. See examples below.
</p>
</li></ul>
</td></tr>
<tr style="vertical-align: top;"><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code>numderiv</code></td>
<td>
<p>string or list of strings indicating the method to use to for the numeric differentiation used in to compute delta method standard errors.
</p>

<ul>
<li><p> &quot;fdforward&quot;: finite difference method with forward differences
</p>
</li>
<li><p> &quot;fdcenter&quot;: finite difference method with central differences (default)
</p>
</li>
<li><p> &quot;richardson&quot;: Richardson extrapolation method
</p>
</li>
<li><p> Extra arguments can be specified by passing a list to the <code>numDeriv</code> argument, with the name of the method first and named arguments following, ex: <code>numderiv=list("fdcenter", eps = 1e-5)</code>. When an unknown argument is used, <code>marginaleffects</code> prints the list of valid arguments for each method.
</p>
</li></ul>
</td></tr>
<tr style="vertical-align: top;"><td style = "white-space: nowrap; font-family: monospace; vertical-align: top"><code>...</code></td>
<td>
<p>Additional arguments are passed to the <code>predict()</code> method
supplied by the modeling package.These arguments are particularly useful
for mixed-effects or bayesian models (see the online vignettes on the
<code>marginaleffects</code> website). Available arguments can vary from model to
model, depending on the range of supported arguments by each modeling
package. See the &quot;Model-Specific Arguments&quot; section of the
<code>?marginaleffects</code> documentation for a non-exhaustive list of available
arguments.</p>
</td></tr>
</table>


## Joint hypothesis tests

<p>The test statistic for the joint Wald test is calculated as (R * theta_hat - r)' * inv(R * V_hat * R') * (R * theta_hat - r) / Q,
where theta_hat is the vector of estimated parameters, V_hat is the estimated covariance matrix, R is a Q x P matrix for testing Q hypotheses on P parameters,
r is a Q x 1 vector for the null hypothesis, and Q is the number of rows in R. If the test is a Chi-squared test, the test statistic is not normalized.
</p>
<p>The p-value is then calculated based on either the F-distribution (for F-test) or the Chi-squared distribution (for Chi-squared test).
For the F-test, the degrees of freedom are Q and (n - P), where n is the sample size and P is the number of parameters.
For the Chi-squared test, the degrees of freedom are Q.
</p>


## Equivalence, Inferiority, Superiority

<p>$\theta$ is an estimate, $\sigma_\theta$ its estimated standard error, and $[a, b]$ are the bounds of the interval supplied to the <code>equivalence</code> argument.
</p>
<p>Non-inferiority:
</p>

<ul>
<li> <p>$H_0$: $\theta \leq a$
</p>
</li>
<li> <p>$H_1$: $\theta > a$
</p>
</li>
<li> <p>$t=(\theta - a)/\sigma_\theta$
</p>
</li>
<li><p> p: Upper-tail probability
</p>
</li></ul>

<p>Non-superiority:
</p>

<ul>
<li> <p>$H_0$: $\theta \geq b$
</p>
</li>
<li> <p>$H_1$: $\theta < b$
</p>
</li>
<li> <p>$t=(\theta - b)/\sigma_\theta$
</p>
</li>
<li><p> p: Lower-tail probability
</p>
</li></ul>

<p>Equivalence: Two One-Sided Tests (TOST)
</p>

<ul>
<li><p> p: Maximum of the non-inferiority and non-superiority p values.
</p>
</li></ul>

<p>Thanks to Russell V. Lenth for the excellent <code>emmeans</code> package and documentation which inspired this feature.
</p>


## Examples
```{r, warning=FALSE, message=FALSE}
library(marginaleffects)

library(marginaleffects)
mod <- lm(mpg ~ hp + wt + factor(cyl), data = mtcars)

# When `FUN` and `hypotheses` are `NULL`, `hypotheses()` returns a data.frame of parameters
hypotheses(mod)

# Test of equality between coefficients
hypotheses(mod, hypothesis = "hp = wt")

# Non-linear function
hypotheses(mod, hypothesis = "exp(hp + wt) = 0.1")

# Robust standard errors
hypotheses(mod, hypothesis = "hp = wt", vcov = "HC3")

# b1, b2, ... shortcuts can be used to identify the position of the
# parameters of interest in the output of FUN
hypotheses(mod, hypothesis = "b2 = b3")

# wildcard
hypotheses(mod, hypothesis = "b* / b2 = 1")

# term names with special characters have to be enclosed in backticks
hypotheses(mod, hypothesis = "`factor(cyl)6` = `factor(cyl)8`")

mod2 <- lm(mpg ~ hp * drat, data = mtcars)
hypotheses(mod2, hypothesis = "`hp:drat` = drat")

# predictions(), comparisons(), and slopes()
mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial)
cmp <- comparisons(mod, newdata = "mean")
hypotheses(cmp, hypothesis = "b1 = b2")

mfx <- slopes(mod, newdata = "mean")
hypotheses(cmp, hypothesis = "b2 = 0.2")

pre <- predictions(mod, newdata = datagrid(hp = 110, mpg = c(30, 35)))
hypotheses(pre, hypothesis = "b1 = b2")

# The `FUN` argument can be used to compute standard errors for fitted values
mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial)

f <- function(x) predict(x, type = "link", newdata = mtcars)
p <- hypotheses(mod, FUN = f)
head(p)

f <- function(x) predict(x, type = "response", newdata = mtcars)
p <- hypotheses(mod, FUN = f)
head(p)

# Complex aggregation
# Step 1: Collapse predicted probabilities by outcome level, for each individual
# Step 2: Take the mean of the collapsed probabilities by group and `cyl`
library(dplyr)
library(MASS)
library(dplyr)

dat <- transform(mtcars, gear = factor(gear))
mod <- polr(gear ~ factor(cyl) + hp, dat)

aggregation_fun <- function(model) {
    predictions(model, vcov = FALSE) |>
        mutate(group = ifelse(group %in% c("3", "4"), "3 &amp; 4", "5")) |>
        summarize(estimate = sum(estimate), .by = c("rowid", "cyl", "group")) |>
        summarize(estimate = mean(estimate), .by = c("cyl", "group")) |>
        rename(term = cyl)
}

hypotheses(mod, FUN = aggregation_fun)

# Equivalence, non-inferiority, and non-superiority tests
mod <- lm(mpg ~ hp + factor(gear), data = mtcars)
p <- predictions(mod, newdata = "median")
hypotheses(p, equivalence = c(17, 18))

mfx <- avg_slopes(mod, variables = "hp")
hypotheses(mfx, equivalence = c(-.1, .1))

cmp <- avg_comparisons(mod, variables = "gear", hypothesis = "pairwise")
hypotheses(cmp, equivalence = c(0, 10))

# joint hypotheses: character vector
model <- lm(mpg ~ as.factor(cyl) * hp, data = mtcars)
hypotheses(model, joint = c("as.factor(cyl)6:hp", "as.factor(cyl)8:hp"))

# joint hypotheses: regular expression
hypotheses(model, joint = "cyl")

# joint hypotheses: integer indices
hypotheses(model, joint = 2:3)

# joint hypotheses: different null hypotheses
hypotheses(model, joint = 2:3, hypothesis = 1)
hypotheses(model, joint = 2:3, hypothesis = 1:2)

# joint hypotheses: marginaleffects object
cmp <- avg_comparisons(model)
hypotheses(cmp, joint = "cyl")


```
